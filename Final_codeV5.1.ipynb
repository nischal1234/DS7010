{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nischal1234/DS7010/blob/colab/Final_codeV5.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accessing google drive"
      ],
      "metadata": {
        "id": "WA9TB-enj3Lq"
      },
      "id": "WA9TB-enj3Lq"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3f00c7be",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:03:22.127231Z",
          "start_time": "2024-02-13T18:03:22.119835Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f00c7be",
        "outputId": "4abdbbcb-6881-4c4e-8e20-95cd2e4cc79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rpEcQ3ugi-XU"
      },
      "id": "rpEcQ3ugi-XU"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "e6f33fae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-08T17:18:36.344724Z",
          "start_time": "2024-02-08T17:18:36.325790Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e6f33fae",
        "outputId": "119b81fb-118a-4214-8231-16f2c8e9ebda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DS7010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "eca7ead1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:03:25.329531Z",
          "start_time": "2024-02-13T18:03:25.318251Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eca7ead1",
        "outputId": "0e2490fb-16cb-46c9-cc55-81e9347b3fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "778de3b7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:03:28.323176Z",
          "start_time": "2024-02-13T18:03:27.829613Z"
        },
        "id": "778de3b7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "0b7fb7c4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:09:16.751557Z",
          "start_time": "2024-02-13T18:09:16.686308Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0b7fb7c4",
        "outputId": "06be22b2-62f4-4240-9712-59c2cb50363a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        _id  activation  valence  dominance emotion  \\\n",
              "0  625699ea1da7a5c1eaef6e63         2.5      2.5        2.5     neu   \n",
              "1  625699ea1da7a5c1eaef6e65         2.5      2.5        2.5     neu   \n",
              "2  625699ea1da7a5c1eaef6e67         2.5      2.5        2.5     neu   \n",
              "3  625699ea1da7a5c1eaef6e69         3.0      2.5        3.0     neu   \n",
              "4  625699ea1da7a5c1eaef6e6a         3.0      2.5        2.5     neu   \n",
              "\n",
              "   start_time  end_time             wav_file  session  \\\n",
              "0      6.2901    8.2357  Ses01F_impro01_F000        1   \n",
              "1     10.0100   11.3925  Ses01F_impro01_F001        1   \n",
              "2     14.8872   18.0175  Ses01F_impro01_F002        1   \n",
              "3     19.2900   20.7875  Ses01F_impro01_F003        1   \n",
              "4     21.3257   24.7400  Ses01F_impro01_F004        1   \n",
              "\n",
              "                                           sentences  \n",
              "0                                         Excuse me.  \n",
              "1                                              Yeah.  \n",
              "2                                Is there a problem?  \n",
              "3                                           You did.  \n",
              "4   You were standing at the beginning and you di...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17aba826-e038-4344-8124-85b684a4f4a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>activation</th>\n",
              "      <th>valence</th>\n",
              "      <th>dominance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>wav_file</th>\n",
              "      <th>session</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>625699ea1da7a5c1eaef6e63</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>neu</td>\n",
              "      <td>6.2901</td>\n",
              "      <td>8.2357</td>\n",
              "      <td>Ses01F_impro01_F000</td>\n",
              "      <td>1</td>\n",
              "      <td>Excuse me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>625699ea1da7a5c1eaef6e65</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>neu</td>\n",
              "      <td>10.0100</td>\n",
              "      <td>11.3925</td>\n",
              "      <td>Ses01F_impro01_F001</td>\n",
              "      <td>1</td>\n",
              "      <td>Yeah.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>625699ea1da7a5c1eaef6e67</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>neu</td>\n",
              "      <td>14.8872</td>\n",
              "      <td>18.0175</td>\n",
              "      <td>Ses01F_impro01_F002</td>\n",
              "      <td>1</td>\n",
              "      <td>Is there a problem?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>625699ea1da7a5c1eaef6e69</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>neu</td>\n",
              "      <td>19.2900</td>\n",
              "      <td>20.7875</td>\n",
              "      <td>Ses01F_impro01_F003</td>\n",
              "      <td>1</td>\n",
              "      <td>You did.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>625699ea1da7a5c1eaef6e6a</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>neu</td>\n",
              "      <td>21.3257</td>\n",
              "      <td>24.7400</td>\n",
              "      <td>Ses01F_impro01_F004</td>\n",
              "      <td>1</td>\n",
              "      <td>You were standing at the beginning and you di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17aba826-e038-4344-8124-85b684a4f4a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17aba826-e038-4344-8124-85b684a4f4a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17aba826-e038-4344-8124-85b684a4f4a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fedce436-192f-4271-a089-97def53233b4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fedce436-192f-4271-a089-97def53233b4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fedce436-192f-4271-a089-97def53233b4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10039,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"62569bef1da7a5c1eaef731b\",\n          \"62569e3b1da7a5c1eaef788f\",\n          \"6256915c1da7a5c1eaef5a12\"\n        ],\n        \"num_unique_values\": 10039,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"activation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7017491569346926,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"samples\": [\n          2.5,\n          4.3333,\n          2.6667\n        ],\n        \"num_unique_values\": 22,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8973109396417046,\n        \"min\": 1.0,\n        \"max\": 5.5,\n        \"samples\": [\n          2.5,\n          4.75,\n          1.3333\n        ],\n        \"num_unique_values\": 21,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dominance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7890997204218619,\n        \"min\": 0.5,\n        \"max\": 5.0,\n        \"samples\": [\n          2.5,\n          0.5,\n          5.0\n        ],\n        \"num_unique_values\": 21,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"oth\",\n          \"fru\",\n          \"exc\"\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.30722264696462,\n        \"min\": 0.4621,\n        \"max\": 539.5758,\n        \"samples\": [\n          36.96,\n          26.0,\n          209.95\n        ],\n        \"num_unique_values\": 9392,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100.63931230101385,\n        \"min\": 3.0025,\n        \"max\": 542.2691,\n        \"samples\": [\n          70.94,\n          210.69,\n          205.6457\n        ],\n        \"num_unique_values\": 9369,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wav_file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Ses04M_impro08_M028\",\n          \"Ses02F_impro08_M010\",\n          \"Ses05F_impro04_M042\"\n        ],\n        \"num_unique_values\": 10039,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \" Yes I did, quite a lot.\",\n          \" You think they can hear us talk?  Or feel the vibrations in the sand when we move around?\",\n          \" Ah, Augie.\"\n        ],\n        \"num_unique_values\": 8068,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "data=pd.read_csv('iemocap_final.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdc4242",
      "metadata": {
        "id": "1cdc4242"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4eb94bb7",
      "metadata": {
        "id": "4eb94bb7"
      },
      "source": [
        "# Testing the Audio files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "30fd5da2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-06T20:06:08.695219Z",
          "start_time": "2024-02-06T20:06:08.682457Z"
        },
        "id": "30fd5da2"
      },
      "outputs": [],
      "source": [
        "iemodata_path='D:/DS7010/IEMOCAP_full_release/IEMOCAP_full_release'\n",
        "iemodata_audio_path='/dialog/wav/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb93d51",
      "metadata": {
        "id": "aeb93d51"
      },
      "source": [
        "Playing audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6311c49c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6311c49c",
        "outputId": "4a2a6784-f9a0-4b52-d0bc-ab1211da28b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "46f6d08f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:10:15.301039Z",
          "start_time": "2024-02-13T18:10:15.297581Z"
        },
        "id": "46f6d08f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "9777f637",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:10:23.083636Z",
          "start_time": "2024-02-13T18:10:23.075817Z"
        },
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9777f637",
        "outputId": "081f3aad-51fd-499d-ab33-3a0857402e17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DS7010/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_impro01/Ses01F_impro01_F004.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "def path_finding_for_audio(file_name,session_number):\n",
        "    #folder_name=file_name\n",
        "    wav_file=file_name + \".wav\"\n",
        "    number=session_number\n",
        "    #as per colab\n",
        "    #sampele location is /content/drive/MyDrive/DS7010/IEMOCAP_full_release\n",
        "    dataset_directory = '/content/drive/MyDrive/DS7010/IEMOCAP_full_release'\n",
        "    sessions_to_play = ['Session1','Session2','Session3','Session4','Session5']\n",
        "    folder_name=extract_folder_name(file_name)\n",
        "    audio_folder = os.path.join(dataset_directory,sessions_to_play[session_number-1],'sentences','wav',folder_name,wav_file)\n",
        "    #check_exist(audio_folder)\n",
        "    return audio_folder\n",
        "\n",
        "def extract_folder_name(file_name):\n",
        "    # Find the index of the underscore before the last character\n",
        "    last_underscore_index = file_name.rfind('_')\n",
        "\n",
        "    # Extract the substring from the beginning of the string up to the last underscore\n",
        "    folder_name = file_name[:last_underscore_index]\n",
        "\n",
        "    return folder_name\n",
        "\n",
        "def check_exist(audio_folder):\n",
        "    if os.path.exists(audio_folder):\n",
        "        print('file exist')\n",
        "    else:\n",
        "        print('not exist')\n",
        "\n",
        "path_finding_for_audio(data.wav_file[4],1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import resampy\n",
        "resampy = lazy.load(\"resampy\")"
      ],
      "metadata": {
        "id": "fNcvtp9824pg",
        "outputId": "20510a30-40a0-424d-e140-9d26d8b091e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "id": "fNcvtp9824pg",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lazy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-d4eb26f5bdb5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresampy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resampy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lazy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import resampy\n",
        "file=path_finding_for_audio(data.wav_file[4],data.session[1])\n",
        "audio, sample_rate = librosa.load(file,res_type='kaiser_fast')"
      ],
      "metadata": {
        "id": "2Cp2a4PkxH9K",
        "outputId": "ef68ac71-8675-4264-e6f2-0972567bc6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "id": "2Cp2a4PkxH9K",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File /usr/local/lib/python3.10/dist-packages/librosa/core/audio.py, line 32, in <module>\n\n----> resampy = lazy.load(\"resampy\")",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-a45b8f1b71d5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_finding_for_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m         )\n\u001b[1;32m    676\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lazy_loader/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__frame_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;34mf\"No module named '{fd['spec']}'\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;34m\"This error is lazily reported, having originally occured in\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File /usr/local/lib/python3.10/dist-packages/librosa/core/audio.py, line 32, in <module>\n\n----> resampy = lazy.load(\"resampy\")",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "XqLpcXjG0yhH",
        "outputId": "00e54761-582a-4d69-f825-54638ea42cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XqLpcXjG0yhH",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ses01F_impro01_F000.wav  Ses01F_impro01_F008.wav  Ses01F_impro01_M000.wav  Ses01F_impro01_M008.wav\n",
            "Ses01F_impro01_F001.wav  Ses01F_impro01_F009.wav  Ses01F_impro01_M001.wav  Ses01F_impro01_M009.wav\n",
            "Ses01F_impro01_F002.wav  Ses01F_impro01_F010.wav  Ses01F_impro01_M002.wav  Ses01F_impro01_M010.wav\n",
            "Ses01F_impro01_F003.wav  Ses01F_impro01_F011.wav  Ses01F_impro01_M003.wav  Ses01F_impro01_M011.wav\n",
            "Ses01F_impro01_F004.wav  Ses01F_impro01_F012.wav  Ses01F_impro01_M004.wav  Ses01F_impro01_M012.wav\n",
            "Ses01F_impro01_F005.wav  Ses01F_impro01_F013.wav  Ses01F_impro01_M005.wav  Ses01F_impro01_M013.wav\n",
            "Ses01F_impro01_F006.wav  Ses01F_impro01_F014.wav  Ses01F_impro01_M006.wav\n",
            "Ses01F_impro01_F007.wav  Ses01F_impro01_F015.wav  Ses01F_impro01_M007.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "1df40465",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-06T21:11:21.932087Z",
          "start_time": "2024-02-06T21:11:21.909023Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "1df40465",
        "outputId": "b5dc479d-233d-49e1-fa4f-3afc8026fc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-b7e792004ef8>:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(file,res_type='kaiser_fast')\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:\\\\DS7010\\\\IEMOCAP_full_release/session1/sentences/wav/Ses01F_impro01/Ses01F_impro01_F004.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'D:\\\\DS7010\\\\IEMOCAP_full_release/session1/sentences/wav/Ses01F_impro01/Ses01F_impro01_F004.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-b7e792004ef8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 )\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-123>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\DS7010\\\\IEMOCAP_full_release/session1/sentences/wav/Ses01F_impro01/Ses01F_impro01_F004.wav'"
          ]
        }
      ],
      "source": [
        "file=path_finding_for_audio(data.wav_file[4],data.session[1])\n",
        "audio, sample_rate = librosa.load(file,res_type='kaiser_fast')\n",
        "mfccs_features_ = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40,n_fft=2048, hop_length=400,center=False)\n",
        "mfccs_features_\n",
        "mfccs_features_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0661075d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:10:31.461719Z",
          "start_time": "2024-02-13T18:10:26.647129Z"
        },
        "id": "0661075d"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9cffc7",
      "metadata": {
        "heading_collapsed": true,
        "id": "cf9cffc7"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f6d102",
      "metadata": {
        "hidden": true,
        "id": "64f6d102"
      },
      "source": [
        "Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d7a9ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-25T20:36:00.716217Z",
          "start_time": "2024-01-25T20:36:00.172011Z"
        },
        "hidden": true,
        "id": "66d7a9ac"
      },
      "outputs": [],
      "source": [
        "#audio_path = 'D:\\DS7010\\IEMOCAP_full_release\\IEMOCAP_full_release\\session1\\dialog\\wav\\Ses01F_impro01.wav'  # Replace with the path to your audio file\n",
        "audio_path=path_finding_for_audio(data.wav_file[4],data.session[1])\n",
        "# Load the audio file\n",
        "audio, sr = librosa.load(audio_path)\n",
        "\n",
        "# Plot the waveform\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(audio, sr=sr)\n",
        "plt.title('Waveform')\n",
        "plt.show()\n",
        "spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n",
        "plt.title('Spectrogram')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcabda2",
      "metadata": {
        "hidden": true,
        "id": "efcabda2"
      },
      "source": [
        "Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d48568",
      "metadata": {
        "hidden": true,
        "id": "b5d48568"
      },
      "outputs": [],
      "source": [
        "audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "\n",
        "# Transpose the MFCCs matrix to have features in columns\n",
        "mfccs = mfccs.T\n",
        "\n",
        "# Create a boxplot using seaborn\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "ax = sns.boxplot(data=mfccs)\n",
        "\n",
        "# Set plot labels and title\n",
        "ax.set(xlabel='MFCC Coefficients', ylabel='Values', title='Boxplot of MFCC Coefficients')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a853afae",
      "metadata": {
        "id": "a853afae"
      },
      "source": [
        "# MFCC"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4a86f7",
      "metadata": {
        "id": "eb4a86f7"
      },
      "source": [
        "MFCC -- Audio Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "c5d7574f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-06T23:36:24.162252Z",
          "start_time": "2024-02-06T23:36:17.436860Z"
        },
        "id": "c5d7574f"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import csv\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "#Keras\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "bbf59a5f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-07T18:08:48.484486Z",
          "start_time": "2024-02-07T18:08:48.432038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bbf59a5f",
        "outputId": "bf91aa56-09c3-4679-d801-8819ac942f3d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'session'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-cfebfbd23453>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#feature extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_finding_for_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute RMSE directly from the waveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'session'"
          ]
        }
      ],
      "source": [
        "#feature extraction\n",
        "songname=path_finding_for_audio(data.wav_file[2],data.session[2])\n",
        "y, sr = librosa.load(songname, mono=True, duration=30)\n",
        "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "# Compute RMSE directly from the waveform\n",
        "rmse = np.sqrt(np.mean(y ** 2))\n",
        "#rmse = librosa.feature.rmse(y=y)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(y)\n",
        "mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "# Now, you need to concatenate all these features into a single feature vector for each audio clip.\n",
        "# Depending on your dataset, you may also need to normalize or scale these features.\n",
        "\n",
        "# For example, if you have extracted features for multiple audio clips, you would stack them vertically to form a feature matrix.\n",
        "#feature_matrix = np.vstack((chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr))\n",
        "print(chroma_stft.shape)\n",
        "print('/n')\n",
        "print(spec_cent.shape)\n",
        "print('/n')\n",
        "print(spec_bw.shape)\n",
        "print('/n')\n",
        "print(rolloff.shape)\n",
        "print('/n')\n",
        "print(zcr.shape)\n",
        "print('/n')\n",
        "print(mfcc.shape)\n",
        "# Then, you can use this feature matrix as input to your sentiment analysis model.\n",
        "#feature_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "3b428888",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-07T19:58:34.950457Z",
          "start_time": "2024-02-07T19:47:35.314534Z"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "3b428888",
        "outputId": "d0302e79-68f6-4e9f-9ac3-96a1f2776816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10039 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'session'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'session'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-46af59c9a58d>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Find the file path for the audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_finding_for_audio_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wav_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Load audio signal and sampling rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'session'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Example feature extraction function\n",
        "def extract_features(y, sr):\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    rmse = np.sqrt(np.mean(y ** 2))\n",
        "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    return chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc\n",
        "\n",
        "# Assuming you have a function `path_finding_for_audio()` that returns the file path\n",
        "def path_finding_for_audio_local(wav_file, session):\n",
        "    # Your code to find the file path\n",
        "    file_path=path_finding_for_audio(wav_file,session)\n",
        "    return file_path\n",
        "\n",
        "# Initialize lists to store extracted features\n",
        "all_chroma_stft = []\n",
        "all_rmse = []\n",
        "all_spec_cent = []\n",
        "all_spec_bw = []\n",
        "all_rolloff = []\n",
        "all_zcr = []\n",
        "all_mfcc = []\n",
        "metadata=data\n",
        "# Iterate over each row in the metadata and extract features\n",
        "for index_num, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
        "    # Find the file path for the audio\n",
        "    file_path = path_finding_for_audio_local(row['wav_file'], row['session'])\n",
        "    # Load audio signal and sampling rate\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    # Extract features\n",
        "    chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc = extract_features(y, sr)\n",
        "    # Pad or truncate feature vectors to match the maximum length\n",
        "    #max_len = max(len(chroma_stft[0]), 1, len(spec_cent), len(spec_bw), len(rolloff), len(zcr), mfcc.shape[1])\n",
        "    max_len=1472\n",
        "    chroma_stft = np.pad(chroma_stft, ((0, 0), (0, max_len - len(chroma_stft[0]))), mode='constant')\n",
        "    rmse = np.array([rmse])\n",
        "    spec_cent = np.pad(spec_cent, (0, max_len - len(spec_cent)), mode='constant')\n",
        "    spec_bw = np.pad(spec_bw, (0, max_len - len(spec_bw)), mode='constant')\n",
        "    rolloff = np.pad(rolloff, (0, max_len - len(rolloff)), mode='constant')\n",
        "    zcr = np.pad(zcr, (0, max_len - len(zcr)), mode='constant')\n",
        "    mfcc = np.pad(mfcc, ((0, 0), (0, max_len - mfcc.shape[1])), mode='constant')\n",
        "    # Append to lists\n",
        "    all_chroma_stft.append(chroma_stft)\n",
        "    all_rmse.append(rmse)\n",
        "    all_spec_cent.append(spec_cent)\n",
        "    all_spec_bw.append(spec_bw)\n",
        "    all_rolloff.append(rolloff)\n",
        "    all_zcr.append(zcr)\n",
        "    all_mfcc.append(mfcc)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_chroma_stft = np.array(all_chroma_stft)\n",
        "all_rmse = np.array(all_rmse)\n",
        "all_spec_cent = np.array(all_spec_cent)\n",
        "all_spec_bw = np.array(all_spec_bw)\n",
        "all_rolloff = np.array(all_rolloff)\n",
        "all_zcr = np.array(all_zcr)\n",
        "all_mfcc = np.array(all_mfcc)\n",
        "\n",
        "# Now, you have arrays with consistent feature vector lengths that you can use for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce5505e8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:22:31.008918Z",
          "start_time": "2024-02-13T18:11:41.814352Z"
        },
        "scrolled": false,
        "id": "ce5505e8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Example feature extraction function\n",
        "def extract_features(y, sr):\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    rmse = np.sqrt(np.mean(y ** 2))\n",
        "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    return chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc\n",
        "\n",
        "# Assuming you have a function `path_finding_for_audio()` that returns the file path\n",
        "def path_finding_for_audio_local(wav_file, session):\n",
        "    # Your code to find the file path\n",
        "    file_path=path_finding_for_audio(wav_file,session)\n",
        "    return file_path\n",
        "\n",
        "# Initialize lists to store extracted features\n",
        "all_chroma_stft = []\n",
        "all_rmse = []\n",
        "all_spec_cent = []\n",
        "all_spec_bw = []\n",
        "all_rolloff = []\n",
        "all_zcr = []\n",
        "all_mfcc = []\n",
        "metadata=data\n",
        "extracted_features=[]\n",
        "# Iterate over each row in the metadata and extract features\n",
        "for index_num, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
        "    # Find the file path for the audio\n",
        "    file_path = path_finding_for_audio_local(row['wav_file'], row['session'])\n",
        "    # Load audio signal and sampling rate\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    # Extract features\n",
        "    chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc = extract_features(y, sr)\n",
        "    # Pad or truncate feature vectors to match the maximum length\n",
        "    #max_len = max(len(chroma_stft[0]), 1, len(spec_cent), len(spec_bw), len(rolloff), len(zcr), mfcc.shape[1])\n",
        "    max_len=1472\n",
        "    chroma_stft = np.pad(chroma_stft, ((0, 0), (0, max_len - len(chroma_stft[0]))), mode='constant')\n",
        "    rmse = np.array([rmse])\n",
        "    spec_cent = np.pad(spec_cent, (0, max_len - len(spec_cent)), mode='constant')\n",
        "    spec_bw = np.pad(spec_bw, (0, max_len - len(spec_bw)), mode='constant')\n",
        "    rolloff = np.pad(rolloff, (0, max_len - len(rolloff)), mode='constant')\n",
        "    zcr = np.pad(zcr, (0, max_len - len(zcr)), mode='constant')\n",
        "    mfcc = np.pad(mfcc, ((0, 0), (0, max_len - mfcc.shape[1])), mode='constant')\n",
        "    # Append to lists\n",
        "    final_class_Lables=row[\"emotion\"]\n",
        "    #datas = features_extractor(file_name)\n",
        "    #extracted_features.append([datas] + final_class_labels)\n",
        "    #extracted_features.append(datas, final_class_Lables)\n",
        "    extracted_features.append([mfcc,chroma_stft,rmse,spec_cent,spec_bw,rolloff,zcr, final_class_Lables])\n",
        "\n",
        "# Converting extracted_features to Pandas DataFrame\n",
        "#extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'emotion', 'activation', 'valence', 'dominance'])\n",
        "extracted_features_df = pd.DataFrame(extracted_features, columns=['mfcc', 'chroma_stft','rmse','spec_cent','spec_bw','rolloff','zcr','emotion'])\n",
        "extracted_features_df\n",
        "\n",
        "# Now, you have arrays with consistent feature vector lengths that you can use for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ce4708",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:24:13.081096Z",
          "start_time": "2024-02-13T18:24:13.069906Z"
        },
        "id": "92ce4708"
      },
      "outputs": [],
      "source": [
        "extracted_features_df.mfcc[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de1aec7",
      "metadata": {
        "id": "5de1aec7"
      },
      "outputs": [],
      "source": [
        "import resampy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24a6ee1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:24:16.294584Z",
          "start_time": "2024-02-13T18:24:16.285920Z"
        },
        "id": "d24a6ee1"
      },
      "outputs": [],
      "source": [
        "df=extracted_features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da181075",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-07T20:38:13.198629Z",
          "start_time": "2024-02-07T20:38:05.607107Z"
        },
        "id": "da181075"
      },
      "outputs": [],
      "source": [
        "#df = pd.DataFrame(extracted_features_df)\n",
        "#df.info()\n",
        "extracted_features_df.to_csv('D:\\\\DS7010\\\\IEMOCAP_full_release\\\\IEMOCAP_full_release\\\\extracted_features_df_all_features.csv',index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c9c820",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:04:30.928291Z",
          "start_time": "2024-02-13T18:04:30.715703Z"
        },
        "id": "f1c9c820"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('D:\\\\DS7010\\\\IEMOCAP_full_release\\\\IEMOCAP_full_release\\\\extracted_features_df_all_features.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fcf8616",
      "metadata": {
        "id": "7fcf8616"
      },
      "source": [
        "Handling categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f7a8f1",
      "metadata": {
        "id": "53f7a8f1"
      },
      "source": [
        "Standardization for all remaining features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece3b1be",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-31T19:22:26.552328Z",
          "start_time": "2024-01-31T19:22:26.349024Z"
        },
        "id": "ece3b1be"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "scale= StandardScaler()\n",
        "extracted_features_df['activation'] = standardization(extracted_features_df['activation'])\n",
        "extracted_features_df['valence'] = standardization(extracted_features_df['valence'])\n",
        "extracted_features_df['dominance'] = standardization(extracted_features_df['dominance'])\n",
        "extracted_features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f075642",
      "metadata": {
        "id": "8f075642"
      },
      "source": [
        "Standardization Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1587de7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-26T22:54:53.899368Z",
          "start_time": "2024-01-26T22:54:53.839624Z"
        },
        "id": "f1587de7"
      },
      "source": [
        "Training and Testing data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c854f958",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-31T22:04:36.884267Z",
          "start_time": "2024-01-31T22:04:36.874780Z"
        },
        "id": "c854f958"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "import pydot\n",
        "visualkeras.layered_view(model, legend=True) # without custom font\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d68c457",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-31T18:28:34.023530Z",
          "start_time": "2024-01-31T18:28:34.018353Z"
        },
        "id": "9d68c457"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b761e2c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-06T21:44:08.416152Z",
          "start_time": "2024-02-06T21:44:06.864069Z"
        },
        "id": "6b761e2c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c1785c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:25:23.277663Z",
          "start_time": "2024-02-13T18:25:23.130769Z"
        },
        "id": "f1c1785c"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd89c141",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:27:26.940899Z",
          "start_time": "2024-02-13T18:27:10.573896Z"
        },
        "id": "fd89c141"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43853c2f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:28:12.855962Z",
          "start_time": "2024-02-13T18:28:12.820956Z"
        },
        "id": "43853c2f"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y=df['emotion']\n",
        "Y = pd.get_dummies(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d358a2ba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:28:36.567966Z",
          "start_time": "2024-02-13T18:28:36.553982Z"
        },
        "id": "d358a2ba"
      },
      "outputs": [],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b7c1eef",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:29:54.760872Z",
          "start_time": "2024-02-13T18:29:54.749307Z"
        },
        "id": "1b7c1eef"
      },
      "outputs": [],
      "source": [
        "df.mfcc[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ddfa5b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:28:51.372823Z",
          "start_time": "2024-02-13T18:28:51.076991Z"
        },
        "id": "5ddfa5b1"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f10222",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:33:42.415209Z",
          "start_time": "2024-02-13T18:33:42.406024Z"
        },
        "id": "57f10222"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e22e818",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:33:45.340834Z",
          "start_time": "2024-02-13T18:33:44.932390Z"
        },
        "id": "9e22e818"
      },
      "outputs": [],
      "source": [
        "#Convolution layers\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(20, 1472,1)))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "#Flattening\n",
        "model.add(Flatten(input_shape=(20, 1472,1)))\n",
        "#1st fully connected Neural Network hidden-layer\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.16))\n",
        "model.add(Activation('relu'))\n",
        "#2nd fully connected Neural Network hidden-layer\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.12))\n",
        "model.add(Activation('relu'))\n",
        "#Output layer\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7c368a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:35:54.817933Z",
          "start_time": "2024-02-13T18:35:54.781584Z"
        },
        "id": "ab7c368a"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer=sgd,\n",
        "metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3447e30f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:07:40.708106Z",
          "start_time": "2024-02-13T19:07:40.700633Z"
        },
        "id": "3447e30f"
      },
      "outputs": [],
      "source": [
        "X=df['mfcc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebb173d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:08:46.157499Z",
          "start_time": "2024-02-13T19:08:46.145039Z"
        },
        "id": "bebb173d"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124abbb8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T18:39:05.200622Z",
          "start_time": "2024-02-13T18:39:05.184445Z"
        },
        "id": "124abbb8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2461ee61",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:07:16.826665Z",
          "start_time": "2024-02-13T19:07:16.813822Z"
        },
        "id": "2461ee61"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da08d3d",
      "metadata": {
        "id": "6da08d3d"
      },
      "source": [
        "# New MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235cf95e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:23:43.772312Z",
          "start_time": "2024-02-13T19:23:34.936293Z"
        },
        "id": "235cf95e"
      },
      "outputs": [],
      "source": [
        "!pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6557fcfd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:24:06.441673Z",
          "start_time": "2024-02-13T19:24:06.419046Z"
        },
        "id": "6557fcfd"
      },
      "outputs": [],
      "source": [
        "from python_speech_features import mfcc\n",
        "from python_speech_features import logfbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0ac438",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:27:51.998642Z",
          "start_time": "2024-02-13T19:27:51.846965Z"
        },
        "id": "1e0ac438"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "data=[]\n",
        "# Example feature extraction function\n",
        "def extract_features(y, sr):\n",
        "    size = 48\n",
        "    X=[]\n",
        "    for i in range(len(data)):\n",
        "    mfcc_feat = mfcc(data[i],rate,nfft=512)\n",
        "    mfcc_feat = np.resize(mfcc_feat, (size,13))\n",
        "    Xmfcc.append(mfcc_feat)\n",
        "    Xmfcc = np.array(X)\n",
        "\n",
        "    return Xmfcc\n",
        "\n",
        "# Assuming you have a function `path_finding_for_audio()` that returns the file path\n",
        "def path_finding_for_audio_local(wav_file, session):\n",
        "    # Your code to find the file path\n",
        "    file_path=path_finding_for_audio(wav_file,session)\n",
        "    return file_path\n",
        "\n",
        "extracted_features=[]\n",
        "# Iterate over each row in the metadata and extract features\n",
        "for index_num, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
        "    # Find the file path for the audio\n",
        "    file_path = path_finding_for_audio_local(row['wav_file'], row['session'])\n",
        "    # Load audio signal and sampling rate\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    # Extract features\n",
        "    data.append(y)\n",
        "    mfcc = extract_features(y, sr)\n",
        "    # Pad or truncate feature vectors to match the maximum length\n",
        "    #max_len = max(len(chroma_stft[0]), 1, len(spec_cent), len(spec_bw), len(rolloff), len(zcr), mfcc.shape[1])\n",
        "\n",
        "    final_class_Lables=row[\"emotion\"]\n",
        "    #datas = features_extractor(file_name)\n",
        "    #extracted_features.append([datas] + final_class_labels)\n",
        "    #extracted_features.append(datas, final_class_Lables)\n",
        "    extracted_features.append([mfcc, final_class_Lables])\n",
        "\n",
        "# Converting extracted_features to Pandas DataFrame\n",
        "#extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'emotion', 'activation', 'valence', 'dominance'])\n",
        "extracted_features_dff = pd.DataFrame(extracted_features, columns=['mfcc','emotion'])\n",
        "extracted_features_dff\n",
        "\n",
        "# Now, you have arrays with consistent feature vector lengths that you can use for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "P3rxkUuFnv-i"
      },
      "id": "P3rxkUuFnv-i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "O8yc1mHNuRtL"
      },
      "id": "O8yc1mHNuRtL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=data\n",
        "print(metadata.iterrows())"
      ],
      "metadata": {
        "id": "qLo7m9BxqYYX"
      },
      "id": "qLo7m9BxqYYX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterrows():\n",
        "  Iterable[tuple[Hashable, Series]]"
      ],
      "metadata": {
        "id": "UU0KRGBUqzHC"
      },
      "id": "UU0KRGBUqzHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def path_finding_for_audio_local(wav_file, session):\n",
        "    # Your code to find the file path\n",
        "    file_path=path_finding_for_audio(wav_file,session)\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "yaZ0hNg_vIbF"
      },
      "id": "yaZ0hNg_vIbF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc10509f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:56:10.596342Z",
          "start_time": "2024-02-13T19:55:56.044782Z"
        },
        "id": "cc10509f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "newdata=[]\n",
        "def path_finding_for_audio_local(wav_file, session):\n",
        "    # Your code to find the file path\n",
        "    file_path=path_finding_for_audio(wav_file,session)\n",
        "    return file_path\n",
        "\n",
        "extracted_features=[]\n",
        "metadata=data\n",
        "# Iterate over each row in the metadata and extract features\n",
        "for index_num, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
        "    # Find the file path for the audio\n",
        "    file_path = path_finding_for_audio_local(row['wav_file'], row['session'])\n",
        "    # Load audio signal and sampling rate\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    #print(sr)\n",
        "\n",
        "    # Extract features\n",
        "    newdata.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568266c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:53:54.380364Z",
          "start_time": "2024-02-13T19:53:54.254490Z"
        },
        "collapsed": true,
        "id": "568266c7"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "id": "gQKgcfsmnEbL"
      },
      "id": "gQKgcfsmnEbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import librosa\n",
        "#from scipy.signal import mfcc\n",
        "Xmfcc = []\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "    mfcc_features = librosa.feature.mfcc(y=data[i], sr=16000)\n",
        "    #mfcc_features = mfcc(data[i], 16000, nfft=512)\n",
        "    mfcc_resized = np.resize(mfcc_features, (size, 13))\n",
        "    Xmfcc.append(mfcc_resized)\n",
        "\n",
        "Xmfccs = np.array(Xmfcc)"
      ],
      "metadata": {
        "id": "la4e2W6dmpCT"
      },
      "id": "la4e2W6dmpCT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b31fd7a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:59:07.911644Z",
          "start_time": "2024-02-13T19:59:07.633955Z"
        },
        "id": "8b31fd7a"
      },
      "outputs": [],
      "source": [
        "metadata=pd.read_csv('iemocap_final.csv')\n",
        "metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "becba1e9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:59:11.949947Z",
          "start_time": "2024-02-13T19:59:11.897062Z"
        },
        "id": "becba1e9"
      },
      "outputs": [],
      "source": [
        "y=metadata['emotion']\n",
        "Y = pd.get_dummies(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0c37dad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:59:21.806622Z",
          "start_time": "2024-02-13T19:59:21.762179Z"
        },
        "id": "a0c37dad"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f546a6e9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:59:46.759514Z",
          "start_time": "2024-02-13T19:59:46.751717Z"
        },
        "id": "f546a6e9"
      },
      "outputs": [],
      "source": [
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f8d7b3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T19:59:54.312375Z",
          "start_time": "2024-02-13T19:59:54.300138Z"
        },
        "id": "f2f8d7b3"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0d661c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:01:48.526998Z",
          "start_time": "2024-02-13T20:01:47.786481Z"
        },
        "id": "bc0d661c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "#Convolution layers\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(48, 13,1)))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "#Flattening\n",
        "model.add(Flatten(input_shape=(48, 13,1)))\n",
        "#1st fully connected Neural Network hidden-layer\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.16))\n",
        "model.add(Activation('relu'))\n",
        "#2nd fully connected Neural Network hidden-layer\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.12))\n",
        "model.add(Activation('relu'))\n",
        "#Output layer\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a456ed9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:02:19.754811Z",
          "start_time": "2024-02-13T20:02:19.696797Z"
        },
        "id": "5a456ed9"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer=sgd,\n",
        "metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5b8c24",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:02:57.047844Z",
          "start_time": "2024-02-13T20:02:57.043800Z"
        },
        "id": "1b5b8c24"
      },
      "outputs": [],
      "source": [
        "X=Xmfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dc11c4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:03:00.897769Z",
          "start_time": "2024-02-13T20:03:00.862008Z"
        },
        "id": "64dc11c4"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
        "x_train = x_train.reshape(-1, size, 13, 1)\n",
        "x_test = x_test.reshape(-1, size, 13, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81d4368",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:03:40.409062Z",
          "start_time": "2024-02-13T20:03:12.163078Z"
        },
        "id": "a81d4368"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "x_train,\n",
        "y_train,\n",
        "epochs=18,\n",
        "batch_size=32,\n",
        "validation_split=0.2,\n",
        "shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946a6fc9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:03:49.452683Z",
          "start_time": "2024-02-13T20:03:49.208304Z"
        },
        "id": "946a6fc9"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ]
    }
  ],
  "metadata": {
    "gist": {
      "data": {
        "description": "Final_code.ipynb",
        "public": false
      },
      "id": ""
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "106px",
        "width": "249.6px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}